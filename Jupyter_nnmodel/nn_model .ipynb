{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenhu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#homemade script\n",
    "from util import Gini\n",
    "from feature_generater import Multiply_Divide, Series_string, Features_Counts, Statistic_features\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#for NN model\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten, Input, Concatenate, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.models import Model\n",
    "from time import time\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data #\n",
    "\n",
    "- Create train, test dataset\n",
    "- Create train target label\n",
    "- Create feature object: cat, num, bin, inter\n",
    "- Create feature columns in train: counting of miss values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_only = True\n",
    "save_cv = True\n",
    "\n",
    "#read data\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "del train['target'], train['id']\n",
    "\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "test_id = test['id']\n",
    "del test['id']\n",
    "\n",
    "\n",
    "\n",
    "#find missing value by each row and recode to column 'missing'\n",
    "train['missing'] = (train==-1).sum(axis=1).astype(float)\n",
    "test['missing'] = (test==-1).sum(axis=1).astype(float)\n",
    "\n",
    "#get all featrue name\n",
    "feature_names = list(train)\n",
    "\n",
    "# extract feature with cat, bin, num, inter\n",
    "cat_fea = [x for x in list(train) if 'cat' in x]\n",
    "bin_fea = [x for x in list(train) if 'bin' in x]\n",
    "num_features = [c for c in list(train) if ('cat' not in c and 'calc' not in c)]\n",
    "inter_fea = [x for x in list(train) if 'inter' in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering #\n",
    "\n",
    "- Create Multipy and Divide feature\n",
    "- Feature of Counts(target incoding)\n",
    "- Load feature generated from Feature Engine\n",
    "- Create Statistic features\n",
    "- Combine all feature together, and get ready for training\n",
    "- Create Cat_feature for NN embeding training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Multipy and Divide feature ##\n",
    "- moltipy each feature in the list and created new columns into train and testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add features of Multiply and Divide\n",
    "features= ['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01']\n",
    "train, test, MD_features = Multiply_Divide(train, test, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inter_0*</th>\n",
       "      <th>inter_0/</th>\n",
       "      <th>inter_1*</th>\n",
       "      <th>inter_1/</th>\n",
       "      <th>inter_2*</th>\n",
       "      <th>inter_2/</th>\n",
       "      <th>inter_3*</th>\n",
       "      <th>inter_3/</th>\n",
       "      <th>inter_4*</th>\n",
       "      <th>inter_4/</th>\n",
       "      <th>...</th>\n",
       "      <th>inter_10*</th>\n",
       "      <th>inter_10/</th>\n",
       "      <th>inter_11*</th>\n",
       "      <th>inter_11/</th>\n",
       "      <th>inter_12*</th>\n",
       "      <th>inter_12/</th>\n",
       "      <th>inter_13*</th>\n",
       "      <th>inter_13/</th>\n",
       "      <th>inter_14*</th>\n",
       "      <th>inter_14/</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.418395</td>\n",
       "      <td>0.176736</td>\n",
       "      <td>0.634544</td>\n",
       "      <td>1.230630</td>\n",
       "      <td>9.720468</td>\n",
       "      <td>0.080334</td>\n",
       "      <td>0.618575</td>\n",
       "      <td>1.262398</td>\n",
       "      <td>1.767358</td>\n",
       "      <td>0.441839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502649</td>\n",
       "      <td>1.025815</td>\n",
       "      <td>1.436141</td>\n",
       "      <td>0.359035</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15.714286</td>\n",
       "      <td>22</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.331716</td>\n",
       "      <td>0.088402</td>\n",
       "      <td>0.474062</td>\n",
       "      <td>0.807773</td>\n",
       "      <td>1.856450</td>\n",
       "      <td>0.206272</td>\n",
       "      <td>0.495053</td>\n",
       "      <td>0.773521</td>\n",
       "      <td>0.618817</td>\n",
       "      <td>0.618817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612862</td>\n",
       "      <td>0.957597</td>\n",
       "      <td>0.766078</td>\n",
       "      <td>0.766078</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.774271</td>\n",
       "      <td>0.071287</td>\n",
       "      <td>-0.641586</td>\n",
       "      <td>-0.641586</td>\n",
       "      <td>7.699029</td>\n",
       "      <td>0.053465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>3.207929</td>\n",
       "      <td>0.128317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>60</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.085898</td>\n",
       "      <td>0.271474</td>\n",
       "      <td>0.315425</td>\n",
       "      <td>0.934592</td>\n",
       "      <td>4.343590</td>\n",
       "      <td>0.067869</td>\n",
       "      <td>0.488654</td>\n",
       "      <td>0.603276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522853</td>\n",
       "      <td>0.645497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.475728</td>\n",
       "      <td>0.673001</td>\n",
       "      <td>5.092484</td>\n",
       "      <td>0.062870</td>\n",
       "      <td>0.396082</td>\n",
       "      <td>0.808331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588531</td>\n",
       "      <td>1.201084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>6.3</td>\n",
       "      <td>12.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inter_0*  inter_0/  inter_1*  inter_1/  inter_2*  inter_2/  inter_3*  \\\n",
       "0  4.418395  0.176736  0.634544  1.230630  9.720468  0.080334  0.618575   \n",
       "1  4.331716  0.088402  0.474062  0.807773  1.856450  0.206272  0.495053   \n",
       "2  5.774271  0.071287 -0.641586 -0.641586  7.699029  0.053465  0.000000   \n",
       "3  1.085898  0.271474  0.315425  0.934592  4.343590  0.067869  0.488654   \n",
       "4  0.000000       inf  0.475728  0.673001  5.092484  0.062870  0.396082   \n",
       "\n",
       "   inter_3/  inter_4*  inter_4/    ...      inter_10*  inter_10/  inter_11*  \\\n",
       "0  1.262398  1.767358  0.441839    ...       0.502649   1.025815   1.436141   \n",
       "1  0.773521  0.618817  0.618817    ...       0.612862   0.957597   0.766078   \n",
       "2       inf  3.207929  0.128317    ...      -0.000000       -inf  -5.000000   \n",
       "3  0.603276  0.000000       inf    ...       0.522853   0.645497   0.000000   \n",
       "4  0.808331  0.000000       inf    ...       0.588531   1.201084   0.000000   \n",
       "\n",
       "   inter_11/  inter_12*  inter_12/  inter_13*  inter_13/  inter_14*  inter_14/  \n",
       "0   0.359035        7.7  15.714286         22   5.500000        1.4   0.350000  \n",
       "1   0.766078        2.4   3.750000          3   3.000000        0.8   0.800000  \n",
       "2  -0.200000        0.0        inf         60   2.400000        0.0   0.000000  \n",
       "3        inf        7.2   8.888889          0        inf        0.0        inf  \n",
       "4        inf        6.3  12.857143          0        inf        0.0        inf  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train[MD_features].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Feature of Counts ##\n",
    "1. Generate new_ind, new_reg, new_car\n",
    "2. Count the number of distinct values of\n",
    "    cat features, new_ind, new_reg and new_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "create 1_0_1_1..... data as new_xxx\n",
    "\n",
    "new_ind: collect all data from all relative \"ind\" columns, then generate series number\n",
    "\n",
    "new_reg, new_car for train and test data \n",
    "For RNN processing, generating a sequence number\n",
    "'''\n",
    "\n",
    "\n",
    "category_list = ['ind', 'reg', 'car']\n",
    "#add 'new_ind','new_reg','new_car' in train and test dataset\n",
    "train, test = Series_string(train,test,category_list )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_ind</th>\n",
       "      <th>new_reg</th>\n",
       "      <th>new_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_2_5_1_0_0_1_0_0_0_0_0_0_0_11_0_1_0</td>\n",
       "      <td>0.7_0.2_0.7180703308</td>\n",
       "      <td>10_1_-1_0_1_4_1_0_0_1_12_2_0.4_0.8836789178_0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1_7_0_0_0_0_1_0_0_0_0_0_0_3_0_0_1</td>\n",
       "      <td>0.8_0.4_0.7660776723</td>\n",
       "      <td>11_1_-1_0_-1_11_1_1_2_1_19_3_0.316227766_0.618...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5_4_9_1_0_0_0_1_0_0_0_0_0_0_12_1_0_0</td>\n",
       "      <td>0.0_0.0_-1.0</td>\n",
       "      <td>7_1_-1_0_-1_14_1_1_2_1_60_1_0.316227766_0.6415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_1_2_0_0_1_0_0_0_0_0_0_0_0_8_1_0_0</td>\n",
       "      <td>0.9_0.2_0.5809475019</td>\n",
       "      <td>7_1_0_0_1_11_1_1_3_1_104_1_0.3741657387_0.5429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_2_0_1_0_1_0_0_0_0_0_0_0_0_9_1_0_0</td>\n",
       "      <td>0.7_0.6_0.840758586</td>\n",
       "      <td>11_1_-1_0_-1_14_1_1_2_1_82_3_0.3160696126_0.56...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                new_ind               new_reg  \\\n",
       "0  2_2_5_1_0_0_1_0_0_0_0_0_0_0_11_0_1_0  0.7_0.2_0.7180703308   \n",
       "1   1_1_7_0_0_0_0_1_0_0_0_0_0_0_3_0_0_1  0.8_0.4_0.7660776723   \n",
       "2  5_4_9_1_0_0_0_1_0_0_0_0_0_0_12_1_0_0          0.0_0.0_-1.0   \n",
       "3   0_1_2_0_0_1_0_0_0_0_0_0_0_0_8_1_0_0  0.9_0.2_0.5809475019   \n",
       "4   0_2_0_1_0_1_0_0_0_0_0_0_0_0_9_1_0_0   0.7_0.6_0.840758586   \n",
       "\n",
       "                                             new_car  \n",
       "0  10_1_-1_0_1_4_1_0_0_1_12_2_0.4_0.8836789178_0....  \n",
       "1  11_1_-1_0_-1_11_1_1_2_1_19_3_0.316227766_0.618...  \n",
       "2  7_1_-1_0_-1_14_1_1_2_1_60_1_0.316227766_0.6415...  \n",
       "3  7_1_0_0_1_11_1_1_3_1_104_1_0.3741657387_0.5429...  \n",
       "4  11_1_-1_0_-1_14_1_1_2_1_82_3_0.3160696126_0.56...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train[['new_ind','new_reg','new_car']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "count_features\n",
    "\n",
    "preparing for train[cat_count_features] \n",
    "cat_fea = \n",
    "['ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat',\n",
    " 'ps_car_03_cat','ps_car_04_cat','ps_car_05_cat','ps_car_06_cat','ps_car_07_cat',\n",
    " 'ps_car_08_cat','ps_car_09_cat','ps_car_10_cat', 'ps_car_11_cat']\n",
    "\n",
    "Example: \n",
    "ps_ind_02_cat_count\n",
    "dictionay of ps_ind_02_cat \n",
    "([(1, 1079327), (2, 309747), (3, 70172), (4, 28259), (-1, 523)])\n",
    "\n",
    "row        count     origial value\n",
    "595202    1079327       1     \n",
    "595203     309747       2\n",
    "595204     309747       2\n",
    "595205      70172       3\n",
    "595206    1079327       1\n",
    "\n",
    "''' \n",
    "\n",
    "cat_fea = [ name for name in list(train) if 'cat' in name and 'count' not in name]\n",
    "features= cat_fea + ['new_ind','new_reg','new_car']\n",
    "\n",
    "train, test, cat_count_features= Features_Counts(train, test, features)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_02_cat_count</th>\n",
       "      <th>ps_ind_04_cat_count</th>\n",
       "      <th>ps_ind_05_cat_count</th>\n",
       "      <th>ps_car_01_cat_count</th>\n",
       "      <th>ps_car_02_cat_count</th>\n",
       "      <th>ps_car_03_cat_count</th>\n",
       "      <th>ps_car_04_cat_count</th>\n",
       "      <th>ps_car_05_cat_count</th>\n",
       "      <th>ps_car_06_cat_count</th>\n",
       "      <th>ps_car_07_cat_count</th>\n",
       "      <th>ps_car_08_cat_count</th>\n",
       "      <th>ps_car_09_cat_count</th>\n",
       "      <th>ps_car_10_cat_count</th>\n",
       "      <th>ps_car_11_cat_count</th>\n",
       "      <th>new_ind_count</th>\n",
       "      <th>new_reg_count</th>\n",
       "      <th>new_car_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>309747</td>\n",
       "      <td>620936</td>\n",
       "      <td>1319412</td>\n",
       "      <td>124587</td>\n",
       "      <td>1234979</td>\n",
       "      <td>1028142</td>\n",
       "      <td>1241334</td>\n",
       "      <td>431560</td>\n",
       "      <td>77845</td>\n",
       "      <td>1383070</td>\n",
       "      <td>249663</td>\n",
       "      <td>486510</td>\n",
       "      <td>1475460</td>\n",
       "      <td>18326</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1079327</td>\n",
       "      <td>866864</td>\n",
       "      <td>1319412</td>\n",
       "      <td>518725</td>\n",
       "      <td>1234979</td>\n",
       "      <td>1028142</td>\n",
       "      <td>1241334</td>\n",
       "      <td>666910</td>\n",
       "      <td>329890</td>\n",
       "      <td>1383070</td>\n",
       "      <td>1238365</td>\n",
       "      <td>883326</td>\n",
       "      <td>1475460</td>\n",
       "      <td>12535</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28259</td>\n",
       "      <td>620936</td>\n",
       "      <td>1319412</td>\n",
       "      <td>449617</td>\n",
       "      <td>1234979</td>\n",
       "      <td>1028142</td>\n",
       "      <td>1241334</td>\n",
       "      <td>666910</td>\n",
       "      <td>147714</td>\n",
       "      <td>1383070</td>\n",
       "      <td>1238365</td>\n",
       "      <td>883326</td>\n",
       "      <td>1475460</td>\n",
       "      <td>19943</td>\n",
       "      <td>24</td>\n",
       "      <td>13477</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1079327</td>\n",
       "      <td>866864</td>\n",
       "      <td>1319412</td>\n",
       "      <td>449617</td>\n",
       "      <td>1234979</td>\n",
       "      <td>183044</td>\n",
       "      <td>1241334</td>\n",
       "      <td>431560</td>\n",
       "      <td>329890</td>\n",
       "      <td>1383070</td>\n",
       "      <td>1238365</td>\n",
       "      <td>36798</td>\n",
       "      <td>1475460</td>\n",
       "      <td>212989</td>\n",
       "      <td>2784</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309747</td>\n",
       "      <td>620936</td>\n",
       "      <td>1319412</td>\n",
       "      <td>518725</td>\n",
       "      <td>1234979</td>\n",
       "      <td>1028142</td>\n",
       "      <td>1241334</td>\n",
       "      <td>666910</td>\n",
       "      <td>147714</td>\n",
       "      <td>1383070</td>\n",
       "      <td>1238365</td>\n",
       "      <td>883326</td>\n",
       "      <td>1475460</td>\n",
       "      <td>26161</td>\n",
       "      <td>258</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ps_ind_02_cat_count  ps_ind_04_cat_count  ps_ind_05_cat_count  \\\n",
       "0               309747               620936              1319412   \n",
       "1              1079327               866864              1319412   \n",
       "2                28259               620936              1319412   \n",
       "3              1079327               866864              1319412   \n",
       "4               309747               620936              1319412   \n",
       "\n",
       "   ps_car_01_cat_count  ps_car_02_cat_count  ps_car_03_cat_count  \\\n",
       "0               124587              1234979              1028142   \n",
       "1               518725              1234979              1028142   \n",
       "2               449617              1234979              1028142   \n",
       "3               449617              1234979               183044   \n",
       "4               518725              1234979              1028142   \n",
       "\n",
       "   ps_car_04_cat_count  ps_car_05_cat_count  ps_car_06_cat_count  \\\n",
       "0              1241334               431560                77845   \n",
       "1              1241334               666910               329890   \n",
       "2              1241334               666910               147714   \n",
       "3              1241334               431560               329890   \n",
       "4              1241334               666910               147714   \n",
       "\n",
       "   ps_car_07_cat_count  ps_car_08_cat_count  ps_car_09_cat_count  \\\n",
       "0              1383070               249663               486510   \n",
       "1              1383070              1238365               883326   \n",
       "2              1383070              1238365               883326   \n",
       "3              1383070              1238365                36798   \n",
       "4              1383070              1238365               883326   \n",
       "\n",
       "   ps_car_10_cat_count  ps_car_11_cat_count  new_ind_count  new_reg_count  \\\n",
       "0              1475460                18326              6             24   \n",
       "1              1475460                12535             36             38   \n",
       "2              1475460                19943             24          13477   \n",
       "3              1475460               212989           2784            222   \n",
       "4              1475460                26161            258             34   \n",
       "\n",
       "   new_car_count  \n",
       "0              1  \n",
       "1             11  \n",
       "2             40  \n",
       "3              1  \n",
       "4             13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(train[['new_ind','new_reg','new_car']].head(5))\n",
    "display(train[cat_count_features].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Get the feature from feature training ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fea0, test_fea0 = pickle.load(open(\"../input/fea0.pk\",'rb'), encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Statistic features ##\n",
    "\n",
    "- find the feature of median, mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature aggregation\n",
    "target_features = ['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01']\n",
    "group_features = ['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01', 'ps_ind_05_cat']\n",
    "\n",
    "#return numpy because we need to do np.hstack to merge all statistic feature together, so that it would return np array\n",
    "train_statis, test_statis =  Statistic_features(train, test, target_features, group_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.57043000e+05,   8.32786207e-01,   2.41530046e-01, ...,\n",
       "          1.00000000e+00,   7.00000000e+00,   0.00000000e+00],\n",
       "       [  1.30452000e+05,   8.26528390e-01,   2.35133348e-01, ...,\n",
       "          1.00000000e+00,   7.00000000e+00,   0.00000000e+00],\n",
       "       [  6.35510000e+04,   8.13168936e-01,   2.35946815e-01, ...,\n",
       "          1.00000000e+00,   7.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  3.58630000e+04,   8.00633360e-01,   2.34463222e-01, ...,\n",
       "          1.00000000e+00,   7.00000000e+00,   0.00000000e+00],\n",
       "       [  2.04836000e+05,   8.24270444e-01,   2.28649975e-01, ...,\n",
       "          1.00000000e+00,   7.00000000e+00,   0.00000000e+00],\n",
       "       [  9.85280000e+04,   8.24453229e-01,   2.37806003e-01, ...,\n",
       "          1.00000000e+00,   7.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_statis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Combine all feature together, and get ready for training ##\n",
    "\n",
    "1. merge features into train_list & test_list that would like to dump into NN model\n",
    "2. training a scaler by sparse that generated by train_list & test_list\n",
    "4. convert train_list & test_list into X , X_test, which has been scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Building a train list including train_num, cat_count_features, statistic feature and infered feature training by XGboost.\n",
    "\n",
    "train_num: training data without set of cat_calc\n",
    "cat_count_features: cat_fea + ['new_ind','new_reg','new_car']\n",
    "train_fea0: feature extraction \n",
    "'''\n",
    "\n",
    "\n",
    "#training data without set of cat_calc\n",
    "train_num = train[[x for x in list(train) if x in num_features]]\n",
    "test_num = test[[x for x in list(train) if x in num_features]]\n",
    "\n",
    "train_list = [train_num.replace([np.inf, -np.inf, np.nan], 0), train[cat_count_features], train_statis, train_fea0 ]\n",
    "test_list = [test_num.replace([np.inf, -np.inf, np.nan], 0), test[cat_count_features], test_statis,test_fea0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "X are stacked from 5 features\n",
    "1. train_num(595212,54): training data without set of cat_calc\n",
    "2. cat_count_features(595212,17): cat_fea + ['new_ind','new_reg','new_car']\n",
    "3. feature statis(595212,6) * 36\n",
    "4. train_fea0(595212, 38): feature extraction\n",
    "\n",
    "all_data (595212, 235)\n",
    "'''\n",
    "\n",
    "\n",
    "X = sparse.hstack(train_list).tocsr()\n",
    "X_test = sparse.hstack(test_list).tocsr()\n",
    "\n",
    "all_data = np.vstack([X.toarray(), X_test.toarray()])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_data)\n",
    "X = scaler.transform(X.toarray())\n",
    "X_test = scaler.transform(X_test.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Create Cat_feature for NN embeding training ##\n",
    " Don't ask why they doing this! they only tell you what is this\n",
    " \n",
    " - in the feature NN model of the finial testing data, you would need the list, which likes **[[cat_featrue], X]**\n",
    " or **[['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat',.....,'ps_car_11_cat'], X]**\n",
    " \n",
    " **_This is to process the above testing data. If you could not understand, that is fine, and just look the next steps_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenhu/anaconda3/envs/run/lib/python3.6/site-packages/pandas/core/indexing.py:630: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "#preparing for training cat \n",
    "train_cat = train[cat_fea]\n",
    "test_cat = test[cat_fea]\n",
    "\n",
    "# convert pd to np.array\n",
    "X_cat = train_cat.values\n",
    "tem = test_cat.values\n",
    "\n",
    "# storing the dimension for embedding layer as an input value\n",
    "max_cat_values = []\n",
    "\n",
    "for c in cat_fea:\n",
    "    \n",
    "    #nomalize the label\n",
    "    #LabelEncoder: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    x = le.fit_transform(pd.concat([train_cat, test_cat])[c])\n",
    "    train_cat.loc[:,c] = le.transform(train_cat[c])\n",
    "    test_cat.loc[:,c] = le.transform(test_cat[c])\n",
    "    max_cat_values.append(np.max(x))\n",
    "\n",
    "# Build the final testing data\n",
    "X_TEST_CAT = []\n",
    "for i in range(tem.shape[1]):\n",
    "    X_TEST_CAT.append(tem[:, i].reshape(-1, 1))\n",
    "X_TEST_CAT.append(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_fea: ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat']\n",
      "\n",
      "max_cat_values:  [4, 2, 7, 12, 2, 2, 9, 2, 17, 2, 1, 5, 2, 103]\n"
     ]
    }
   ],
   "source": [
    "print('cat_fea:', cat_fea)\n",
    "print('\\nmax_cat_values: ',max_cat_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training NN Model with Keras # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build the model\n",
    "2. training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Build the model ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model structure:  ###\n",
    "<img src=\"Jupyter_image/NN_layer.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    inputs = []\n",
    "    flatten_layers = []\n",
    "    for e, c in enumerate(cat_fea):\n",
    "        input_c = Input(shape=(1, ), dtype='int32')\n",
    "        num_c = max_cat_values[e]\n",
    "        \n",
    "        # need to add 1, https://keras.io/layers/embeddings/\n",
    "        # **input_dim: int > 0. Size of the vocabulary, i.e. maximum integer index + 1.**\n",
    "        embed_c = Embedding(num_c+1,6,input_length=1)(input_c)\n",
    "        embed_c = Dropout(0.25)(embed_c)\n",
    "        flatten_c = Flatten()(embed_c)\n",
    "        inputs.append(input_c)\n",
    "        flatten_layers.append(flatten_c)\n",
    "        \n",
    "    \n",
    "    input_num = Input(shape=(X.shape[1],), dtype='float32')\n",
    "    inputs.append(input_num)\n",
    "    \n",
    "    #merge X and embedding layer\n",
    "    flatten_layers.append(input_num)\n",
    "    flatten = merge(flatten_layers, mode='concat')\n",
    "\n",
    "    fc1 = Dense(512, kernel_initializer='he_normal')(flatten)\n",
    "    fc1 = PReLU()(fc1)\n",
    "    fc1 = BatchNormalization()(fc1)\n",
    "    fc1 = Dropout(0.75)(fc1)\n",
    "\n",
    "    fc1 = Dense(64, kernel_initializer='he_normal')(fc1)\n",
    "    fc1 = PReLU()(fc1)\n",
    "    fc1 = BatchNormalization()(fc1)\n",
    "    fc1 = Dropout(0.5)(fc1)\n",
    "\n",
    "    outputs = Dense(1, kernel_initializer='he_normal', activation='sigmoid')(fc1)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Start to Train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenhu/anaconda3/envs/run/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Users/stevenhu/anaconda3/envs/run/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 297606 samples, validate on 297606 samples\n",
      "Epoch 1/1\n",
      " - 27s - loss: 0.3061 - val_loss: 0.1639\n",
      "local fold Gini:  0.209322322663\n",
      "Train on 297606 samples, validate on 297606 samples\n",
      "Epoch 1/1\n",
      " - 28s - loss: 0.3087 - val_loss: 0.1645\n",
      "local fold Gini:  0.201585256464\n",
      "seed 0: Gini 0.20545379936910999\n",
      "Total training time:  0:01:55.265348\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#validation fold\n",
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "\n",
    "I change \"test\" to \"vaild\" because I feel it is clear to understand\n",
    "\"\"\"\n",
    "\n",
    "cv_train = np.zeros(len(train_label))\n",
    "cv_pred = np.zeros(len(test_id))\n",
    "\n",
    "#validation fold\n",
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "\n",
    "#with different random see make result stable.\n",
    "num_seeds = 5\n",
    "begintime = time()\n",
    "if cv_only:\n",
    "    for s in range(num_seeds):\n",
    "        np.random.seed(s)\n",
    "        for (train_index, valid_index) in kfold.split(X, train_label):\n",
    "            \n",
    "            #assign data from training data and labels to validation data; \n",
    "            x_train = X[train_index]\n",
    "            y_train = train_label[train_index]\n",
    "            x_valid= X[valid_index]\n",
    "            y_valid = train_label[valid_index]\n",
    "            \n",
    "            # assign X_cat to validation data; \n",
    "            x_train_cat = X_cat[train_index]\n",
    "            x_valid_cat = X_cat[valid_index]\n",
    "\n",
    "            #Package data for training, the package(list) is  [[cat_featrues], x_train] \n",
    "            # or [ ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat',.....,'ps_car_11_cat'] ,x_train]\n",
    "            \n",
    "            x_train_cat_list, x_valid_cat_list = [], []\n",
    "            for i in range(x_train_cat.shape[1]):\n",
    "                x_train_cat_list.append(x_train_cat[:, i].reshape(-1, 1))\n",
    "                x_valid_cat_list.append(x_valid_cat[:, i].reshape(-1, 1))\n",
    "\n",
    "            x_train_cat_list.append(x_train)\n",
    "            x_valid_cat_list.append(x_valid)\n",
    "            \n",
    "            #load model\n",
    "            model = nn_model()\n",
    "            \n",
    "            def get_rank(x):\n",
    "                return pd.Series(x).rank(pct=True).values\n",
    "            #fit model. Note: Change epochs to make prediction accuracy\n",
    "            model.fit(x_train_cat_list, y_train, epochs=10, batch_size=512, verbose=2, validation_data=[x_valid_cat_list, y_valid])\n",
    "            \n",
    "            #record prediction with validation data\n",
    "            cv_train[valid_index] += get_rank(model.predict(x=x_valid_cat_list, batch_size=512, verbose=0)[:, 0])\n",
    "            print('local fold Gini: ',Gini(train_label[valid_index], cv_train[valid_index]))\n",
    "            \n",
    "            #recode prediction with testing data\n",
    "            cv_pred += get_rank(model.predict(x=X_TEST_CAT, batch_size=512, verbose=0)[:, 0])\n",
    "             \n",
    "            \n",
    "        \n",
    "        print(\"seed {0}: Gini {1}\".format(s,Gini(train_label, cv_train / (1. * (s + 1)))))\n",
    "        print(\"Total training time: \",str(datetime.timedelta(seconds=time() - begintime)))\n",
    "    if save_cv:\n",
    "        \n",
    "        #divid (NFOLDS * num_seeds) to get average of probablity \n",
    "        pd.DataFrame({'id': test_id, 'target': get_rank(cv_pred * 1./ (NFOLDS * num_seeds))}).to_csv('../model/keras5_pred.csv', index=False)\n",
    "        pd.DataFrame({'id': train_id, 'target': get_rank(cv_train * 1. / num_seeds)}).to_csv('../model/keras5_cv.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
